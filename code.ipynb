{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = config[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = ''' \n",
    "def remove_common_prefix(x, prefix, ws_prefix):\n",
    "    x[\"completion\"] = x[\"completion\"].str[len(prefix):]\n",
    "    if ws_prefix:\n",
    "        #keep the single whitespasce as prefix \n",
    "        x[\"completion\"] = \" \" + x[\"completion\"]\n",
    "return x\n",
    "''' \n",
    "\n",
    "messages = [\n",
    "    {\"role\":\"system\", \"content\": \"you are a python explaining assistant. Be explicit\"},\n",
    "    {\"role\":\"user\", \"content\": f\"explain the following function: {func}\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    messages = messages,\n",
    "    model = \"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Python function called \"remove_common_prefix\". It takes three arguments: \"x\", \"prefix\", and \"ws_prefix\". \n",
      "\n",
      "The argument \"x\" is expected to be a pandas DataFrame, as it accesses the column \"completion\" from it. The \"prefix\" argument is a string that represents the common prefix to remove from the completion column. The \"ws_prefix\" is a boolean that indicates whether we want to keep a single whitespace character as a prefix after removing the common prefix.\n",
      "\n",
      "The function first removes the common prefix from the \"completion\" column by using the Pandas string method \"str[len(prefix):]\", which returns a substring of the text starting from the length of the prefix to the end. Then, if \"ws_prefix\" is True, it adds a single whitespace character as a prefix to each row's \"completion\" column.\n",
      "\n",
      "Finally, the function returns the modified \"x\" DataFrame.\n"
     ]
    }
   ],
   "source": [
    "print(res[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Complexities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble_sort = ''' \n",
    "def sort(array):\n",
    "    for i in range(len(array)):\n",
    "        for j in range(0, len(array)-i-1):\n",
    "            if array[j]>array[j+1]:\n",
    "                temp =array[j]\n",
    "                array[j]= array[j+1]\n",
    "                array[j+1] = temp \n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_sort = '''\n",
    "def partiion(array, low, high):\n",
    "    pivot = array[high]\n",
    "    i = low -1 \n",
    "\n",
    "    for j in range(low, high):\n",
    "        if array[j] <= pivot:\n",
    "            i = i + 1\n",
    "            (array[i], array[j]) = (array[j], array[i])\n",
    "    (array[i+1], array[high]) = (array[high], array[i+1])\n",
    "    return i + 1\n",
    "\n",
    "def sort(array, low, high):\n",
    "    if low < high:\n",
    "        pi = partition(array, low, high)\n",
    "        sort(array, low, pi-1)\n",
    "        sort(array, pi+1, high)\n",
    "''' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\":\"user\", \"content\": f\"Calculate the time complexity of the following function: {bubble_sort}\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time complexity of the given function is O(n^2), where n is the length of the input array.\n",
      "\n",
      "The outer loop iterates over the entire array once, so it has a time complexity of O(n).\n",
      "\n",
      "The inner loop iterates over the entire array except for the last i elements, where i is the index of the current iteration of the outer loop. On average, this loop will iterate n/2 times, so it has a time complexity of O(n/2), which is equivalent to O(n).\n",
      "\n",
      "The operations inside the inner loop (comparison and swap) are constant time operations, so their time complexity is O(1).\n",
      "\n",
      "Combining these time complexity analyses, we get:\n",
      "\n",
      "- The outer loop has a time complexity of O(n).\n",
      "- The inner loop has a time complexity of O(n).\n",
      "- The operations inside the inner loop have a time complexity of O(1).\n",
      "\n",
      "Therefore, the overall time complexity of the function is O(n^2).\n"
     ]
    }
   ],
   "source": [
    "res2 = openai.ChatCompletion.create(\n",
    "    messages = messages,\n",
    "    model = \"gpt-3.5-turbo\"\n",
    ")\n",
    "print(res2[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\":\"user\", \"content\": f\"Calculate the time complexity of the following function: {quick_sort}\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time complexity of the partition function is O(n), where n is the length of the array. The for loop runs n-1 times, and each operation within the loop takes constant time.\n",
      "\n",
      "The time complexity of the sort function is O(n*log(n)), where n is the length of the array. This is because the function recursively divides the array into smaller arrays, each of size at most n-1, and then sorts each sub-array using the partition function. The number of recursive calls is log(n) (base 2), as each call splits the array in half. Therefore, the time complexity of sort function can be expressed as O(n*log(n)).\n",
      "\n",
      "Overall, the time complexity of the entire code is O(n*log(n)), which is dominated by the time complexity of the sort function.\n"
     ]
    }
   ],
   "source": [
    "res3 = openai.ChatCompletion.create(\n",
    "    messages = messages,\n",
    "    model = \"gpt-3.5-turbo\"\n",
    ")\n",
    "print(res3[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asking GPT4 To Translate JS to Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "js = \"\"\"\n",
    "function mystery(arr) {\n",
    "  return arr.reduce(function (p, v) {\n",
    "    return ( p < v ? p : v );\n",
    "  });\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\":\"user\", \"content\": f\"translate the following JavaScript to Python:{js}\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def mystery(arr):\n",
      "    return reduce(lambda p, v: p if p < v else v, arr)\n"
     ]
    }
   ],
   "source": [
    "res4 = openai.ChatCompletion.create(\n",
    "    messages = messages,\n",
    "    model = \"gpt-3.5-turbo\"\n",
    ")\n",
    "print(res4[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "js2 = \"\"\"\n",
    "const mystery = (email) => {\n",
    "  const regex = /^\\S+@\\S+\\.\\S+$/;\n",
    "  return regex.test(email);\n",
    "};\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\":\"user\", \"content\": f\"translate the following JavaScript to Python:{js2}\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import re\n",
      "\n",
      "def mystery(email):\n",
      "    regex = re.compile(r'^\\S+@\\S+\\.\\S+$')\n",
      "    return regex.match(email) is not None\n"
     ]
    }
   ],
   "source": [
    "res5 = openai.ChatCompletion.create(\n",
    "    messages = messages,\n",
    "    model = \"gpt-3.5-turbo\"\n",
    ")\n",
    "print(res5[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "js3 = \"\"\"\n",
    "const mystery = (str) => {\n",
    "  const arr = str.trim().toLowerCase().split(\" \");\n",
    "\n",
    "  for (let i = 0; i < arr.length; i++) {\n",
    "    arr[i] = arr[i].charAt(0).toUpperCase() + arr[i].slice(1);\n",
    "  }\n",
    "\n",
    "  return arr.join(\" \");\n",
    "};\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\":\"user\", \"content\": f\"translate the following JavaScript to Python:{js3}\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def mystery(str):\n",
      "    arr = str.strip().lower().split(\" \")\n",
      "    for i in range(len(arr)):\n",
      "        arr[i] = arr[i].capitalize()\n",
      "    return \" \".join(arr)\n"
     ]
    }
   ],
   "source": [
    "res6 = openai.ChatCompletion.create(\n",
    "    messages = messages,\n",
    "    model = \"gpt-3.5-turbo\"\n",
    ")\n",
    "print(res6[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mystery(str):\n",
    "    arr = str.strip().lower().split(\" \")\n",
    "    for i in range(len(arr)):\n",
    "        arr[i] = arr[i].capitalize()\n",
    "    return \" \".join(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I Like To Eat Chicken'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystery(\"i like to eat chicken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def mystery2(email):\n",
    "    regex = re.compile(r'^\\S+@\\S+\\.\\S+$')\n",
    "    return regex.match(email) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystery2(\"todd@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystery2(\"t@dasd\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT4 Bug Finder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = ''' \n",
    "def add_underscores(word):\n",
    "    new_wrod = \"_\"\n",
    "    for i in range(len(word)):\n",
    "        new_word = word[i] + \"_\"\n",
    "    return new_word \n",
    "\n",
    "phrase = \"hello\"\n",
    "print(add_underscores(phrase))\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"Fix and explain the bug in the following python code:{code}\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bug in the code is in the for loop inside the add_underscores function. It is repeatedly updating the new_word variable instead of concatenating the letters to it. \n",
      "\n",
      "Here's the fixed code:\n",
      "\n",
      "def add_underscores(word):\n",
      "    new_word = \"_\"\n",
      "    for i in range(len(word)):\n",
      "        new_word += word[i] + \"_\"\n",
      "    return new_word \n",
      "\n",
      "phrase = \"hello\"\n",
      "print(add_underscores(phrase))\n",
      "\n",
      "Output:\n",
      "_h_e_l_l_o_ \n",
      "\n",
      "Explanation: \n",
      "The add_underscores() function takes a word as input and returns a new string with underscores (_) between each letter of the input word.\n",
      "\n",
      "In the original code, the variable new_word was initialized to \"_\" but was never used. Inside the for loop, the variable new_word was repeatedly updated with each letter of the input word, which resulted in only the last letter of the word being returned.\n",
      "\n",
      "In the fixed code, the variable new_word is initialized to \"_\" and each letter of the input word is concatenated to it with an underscore in between using the \"+=\" operator. Finally, the completed new_word with underscores is returned by the function.\n"
     ]
    }
   ],
   "source": [
    "res7 = openai.ChatCompletion.create(\n",
    "    messages = messages,\n",
    "    model = \"gpt-3.5-turbo\"\n",
    ")\n",
    "print(res7[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_h_e_l_l_o_\n"
     ]
    }
   ],
   "source": [
    "def add_underscores(word):\n",
    "    new_word = \"_\"\n",
    "    for i in range(len(word)):\n",
    "        new_word += word[i] + \"_\"\n",
    "    return new_word \n",
    "\n",
    "phrase = \"hello\"\n",
    "print(add_underscores(phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "code2 = ''' \n",
    "import Random \n",
    "a = random.randint(1,12)\n",
    "b = random.randint(1, 12)\n",
    "\n",
    "for i in range(10):\n",
    "    question = \"what is \"+a+\" x \"+b+\"? \"\n",
    "    answer = input(question)\n",
    "    if answer = a*b:\n",
    "        print (Well done!)\n",
    "    else:\n",
    "        print(\"No.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"Fix and explain the bug in the following python code:{code2}\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a few bugs in this code:\n",
      "\n",
      "1. The import statement at the beginning of the code has a capital \"R\" in \"Random\", but the actual module name should be lowercase: \"random\".\n",
      "2. In the for loop, the variable \"i\" is not being used, so it can be removed.\n",
      "3. The variables \"a\" and \"b\" are being generated outside of the loop, so they will not change for each iteration of the loop. They should be moved inside the loop so that new values are generated each time.\n",
      "4. In the question string, the variables \"a\" and \"b\" are integers, but they need to be converted to strings before they can be concatenated with the other strings. This can be done using the str() function.\n",
      "5. In the if statement, a single equals sign is being used to check for equality, but this is incorrect in Python. To check for equality, you should use two equals signs (==).\n",
      "6. The string \"Well done!\" should be enclosed in quotes.\n",
      "\n",
      "Here's the corrected code:\n",
      "\n",
      "import random\n",
      "\n",
      "for i in range(10):\n",
      "    a = random.randint(1, 12)\n",
      "    b = random.randint(1, 12)\n",
      "    question = \"what is \" + str(a) + \" x \" + str(b) + \"? \"\n",
      "    answer = input(question)\n",
      "    if answer == str(a*b):\n",
      "        print(\"Well done!\")\n",
      "    else:\n",
      "        print(\"No.\")\n"
     ]
    }
   ],
   "source": [
    "res8 = openai.ChatCompletion.create(\n",
    "    messages = messages,\n",
    "    model = \"gpt-3.5-turbo\"\n",
    ")\n",
    "print(res8[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.\n",
      "Well done!\n",
      "Well done!\n",
      "Well done!\n",
      "No.\n",
      "No.\n",
      "No.\n",
      "No.\n",
      "No.\n",
      "No.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    a = random.randint(1, 12)\n",
    "    b = random.randint(1, 12)\n",
    "    question = \"what is \" + str(a) + \" x \" + str(b) + \"? \"\n",
    "    answer = input(question)\n",
    "    if answer == str(a*b):\n",
    "        print(\"Well done!\")\n",
    "    else:\n",
    "        print(\"No.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask GPT4 TO Write Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"Write a Python function that accepts an RGB color in the format 'rgb(85,145,0)' and returns the corresponding HSL color in the format 'hsl(85 100% 28%)'\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI language model, I cannot create functions in Python. However, here's an example of how to convert RGB to HSL using Python:\n",
      "\n",
      "```python\n",
      "def rgb_to_hsl(rgb):\n",
      "    # split RGB values from the string\n",
      "    rgb = rgb.strip('rgb(').strip(')').split(',')\n",
      "    r = int(rgb[0]) / 255\n",
      "    g = int(rgb[1]) / 255\n",
      "    b = int(rgb[2]) / 255\n",
      "    \n",
      "    # calculate the luminance values\n",
      "    cmin = min(r, g, b)\n",
      "    cmax = max(r, g, b)\n",
      "    delta = cmax - cmin\n",
      "    l = (cmax + cmin) / 2\n",
      "    \n",
      "    # calculate the hue and saturation values\n",
      "    if delta == 0:\n",
      "        h = 0\n",
      "        s = 0\n",
      "    else:\n",
      "        if l < 0.5:\n",
      "            s = delta / (cmax + cmin)\n",
      "        else:\n",
      "            s = delta / (2 - cmax - cmin)\n",
      "        \n",
      "        if r == cmax:\n",
      "            h = (g - b) / delta\n",
      "        elif g == cmax:\n",
      "            h = 2 + (b - r) / delta\n",
      "        else:\n",
      "            h = 4 + (r - g) / delta\n",
      "        \n",
      "        h *= 60\n",
      "        if h < 0:\n",
      "            h += 360\n",
      "    \n",
      "    # format the HSL string and return\n",
      "    return \"hsl({}, {}%, {}%)\".format(int(h), int(s * 100), int(l * 100))\n",
      "```\n",
      "\n",
      "Simply call this function with the RGB color as a parameter, and it will return the corresponding HSL color. For example:\n",
      "\n",
      "```python\n",
      ">>> rgb_to_hsl('rgb(85,145,0)')\n",
      "'hsl(85, 100%, 28%)'\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "res9 = openai.ChatCompletion.create(\n",
    "    messages = messages,\n",
    "    model = \"gpt-3.5-turbo\"\n",
    ")\n",
    "print(res9[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hsl(rgb):\n",
    "    # split RGB values from the string\n",
    "    rgb = rgb.strip('rgb(').strip(')').split(',')\n",
    "    r = int(rgb[0]) / 255\n",
    "    g = int(rgb[1]) / 255\n",
    "    b = int(rgb[2]) / 255\n",
    "    \n",
    "    # calculate the luminance values\n",
    "    cmin = min(r, g, b)\n",
    "    cmax = max(r, g, b)\n",
    "    delta = cmax - cmin\n",
    "    l = (cmax + cmin) / 2\n",
    "    \n",
    "    # calculate the hue and saturation values\n",
    "    if delta == 0:\n",
    "        h = 0\n",
    "        s = 0\n",
    "    else:\n",
    "        if l < 0.5:\n",
    "            s = delta / (cmax + cmin)\n",
    "        else:\n",
    "            s = delta / (2 - cmax - cmin)\n",
    "        \n",
    "        if r == cmax:\n",
    "            h = (g - b) / delta\n",
    "        elif g == cmax:\n",
    "            h = 2 + (b - r) / delta\n",
    "        else:\n",
    "            h = 4 + (r - g) / delta\n",
    "        \n",
    "        h *= 60\n",
    "        if h < 0:\n",
    "            h += 360\n",
    "    \n",
    "    # format the HSL string and return\n",
    "    return \"hsl({}, {}%, {}%)\".format(int(h), int(s * 100), int(l * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hsl(84, 100%, 28%)'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rgb_to_hsl(\"85, 145, 0\")\n",
    "rgb_to_hsl('rgb(85,145,0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hsl(rgb_str):\n",
    "    import re\n",
    "    \n",
    "    # Extract RGB values from the input string\n",
    "    r, g, b = map(int, re.findall(r'\\d+', rgb_str))\n",
    "\n",
    "    # Normalize RGB values to the range [0, 1]\n",
    "    r /= 255.0\n",
    "    g /= 255.0\n",
    "    b /= 255.0\n",
    "\n",
    "    # Calculate min, max, and chroma\n",
    "    min_val = min(r, g, b)\n",
    "    max_val = max(r, g, b)\n",
    "    chroma = max_val - min_val\n",
    "\n",
    "    # Calculate hue\n",
    "    if chroma == 0:\n",
    "        hue = 0\n",
    "    elif max_val == r:\n",
    "        hue = (60 * ((g - b) / chroma) + 360) % 360\n",
    "    elif max_val == g:\n",
    "        hue = (60 * ((b - r) / chroma) + 120) % 360\n",
    "    else:  # max_val == b\n",
    "        hue = (60 * ((r - g) / chroma) + 240) % 360\n",
    "\n",
    "    # Calculate lightness\n",
    "    lightness = (max_val + min_val) / 2\n",
    "\n",
    "    # Calculate saturation\n",
    "    if chroma == 0:\n",
    "        saturation = 0\n",
    "    else:\n",
    "        saturation = chroma / (1 - abs(2 * lightness - 1))\n",
    "\n",
    "    # Convert hue, saturation, and lightness to string format\n",
    "    hsl_str = f\"hsl({int(round(hue))}, {int(round(saturation * 100))}%, {int(round(lightness * 100))}%)\"\n",
    "    return hsl_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hsl(85, 100%, 28%)\n"
     ]
    }
   ],
   "source": [
    "rgb_color = \"rgb(85, 145, 0)\"\n",
    "hsl_color = rgb_to_hsl(rgb_color)\n",
    "print(hsl_color)  # Output: 'hsl(85, 100%, 28%)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
